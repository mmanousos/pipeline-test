---
version: "3.2"
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:5.4.1
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - 22181:22181
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 22181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - kafka
    
  broker:
    image: confluentinc/cp-kafka:latest
    hostname: broker
    container_name: broker
    depends_on:
      - zookeeper
    ports:
      - 9092:9092
      - 29092:29092
    environment:
      # parameters here:
      # https://kafka.apache.org/documentation/#configuration
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:22181
      # KAFKA_ADVERTISED_LISTENERS is a comma-separated list of listeners with their
      # host/IP and port. This is the metadata thatâ€™s passed back to clients.
      # https://www.confluent.io/blog/kafka-listeners-explained/
      # the use of PLAINTEXT is related to the security.inter.broker.protocol: 
      # https://docs.confluent.io/current/installation/configuration/broker-configs.html
      
      # adapted from RMoffatt blog post
      KAFKA_LISTENERS: INTERNAL://broker:29092,EXTERNAL://broker:9092,INTERNAL_ALT://broker:29092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://broker:29092,EXTERNAL://localhost:9092,INTERNAL_ALT://alt:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,INTERNAL_ALT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # KAFKA_LISTENERS: PLAINTEXT://broker:29093,PLAINTEXT_HOST://localhost:9092
      # KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29093,PLAINTEXT_HOST://localhost:9092
      # # KAFKA_ADVERTISED_LISTENERS: INSIDE://:9092,OUTSIDE://127.0.0.1:9094
      # KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      # KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      # KAFKA_METRIC_REPORTERS: io.confluent.metrics.reporter.ConfluentMetricsReporter
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      # KAFKA_CONFLUENT_LICENSE_TOPIC_REPLICATION_FACTOR: 1
      # KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      # CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
      # CONFLUENT_METRICS_REPORTER_ZOOKEEPER_CONNECT: zookeeper:22181
      # CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      # CONFLUENT_METRICS_ENABLE: "true"
      # CONFLUENT_SUPPORT_CUSTOMER_ID: "anonymous"
      # settings to prevent timeout while running on a single broker
      TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      TRANSCATION_STATE_LOG_MIN_ISR: 1
      OFFSET_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - broker1-data:/var/lib/kafka/data  
    networks:
      - kafka

  #     marking out additional brokers for now
  # broker-2:
  #   image: confluentinc/cp-kafka:latest
  #   hostname: broker-2
  #   container_name: broker-2
  #   depends_on:
  #     - zookeeper
  #   ports:
  #     - 29093:29093
  #     - 9093:9093
  #   environment:
  #     KAFKA_BROKER_ID: 2
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:22181
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-2:29093,PLAINTEXT_HOST://localhost-2:9093
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #   volumes:
  #     - broker2-data:/var/lib/kafka/data
  #   networks:
  #     - kafka

  # broker-3:
  #   image: confluentinc/cp-kafka:latest
  #   hostname: broker-3
  #   container_name: broker-3
  #   depends_on:
  #     - zookeeper
  #   ports:
  #     - 29094:29094
  #     - 9094:9094
  #   environment:
  #     KAFKA_BROKER_ID: 3
  #     KAFKA_ZOOKEEPER_CONNECT: zookeeper:22181
  #     KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker-3:29094,PLAINTEXT_HOST://localhost-3:9094
  #     KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
  #     KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
  #     KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  #   volumes:
  #     - broker3-data:/var/lib/kafka/data
  #   networks:
  #     - kafka
    
  schema-registry:
    image: confluentinc/cp-schema-registry:5.4.1
    hostname: schema-registry
    container_name: schema-registry
    depends_on:
      - broker
    ports:
      - 8081:8081
      - 28081:28081
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      # zookeeper election is deprecated, use kafka instead
      # https://docs.confluent.io/current/schema-registry/installation/config.html#kafkastore-bootstrap-servers
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://broker:29092 #,PLAINTEXT://broker:29093,PLAINTEXT://broker:29094
      # Comma-separated list of listeners that listen for API requests over
      # either HTTP or HTTPS. If a listener uses HTTPS, the appropriate SSL
      # configuration parameters need to be set as well.
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:28081,http://0.0.0.0:8081,http://localhost:8081
      DEBUG: "true"
    networks:
      - kafka

  kafka-connect:
    image: confluentinc/cp-kafka-connect-base:5.4.1
    container_name: kafka-connect
    depends_on:
      - broker
      - schema-registry
    ports:
      - 8083:8083
      - 28083:28083
    environment:
      CONNECT_BOOTSTRAP_SERVERS: broker:29092 #,broker-2:29093,broker-3:29094,localhost:9092,localhost-2:9093,localhost-3:9094 
      CONNECT_REST_ADVERTISED_HOST_NAME: "kafka-connect"
      CONNECT_REST_PORT: 8083
      CONNECT_GROUP_ID: kafka-connect
      CONNECT_CONFIG_STORAGE_TOPIC: _kafka-connect-configs
      CONNECT_OFFSET_STORAGE_TOPIC: _kafka-connect-offsets
      CONNECT_STATUS_STORAGE_TOPIC: _kafka-connect-status
      CONNECT_KEY_CONVERTER: io.confluent.connect.avro.AvroConverter ## this is the default key converter. This is why sometimes there is no key.converter config. They are just using default.
      CONNECT_KEY_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:28081"
      CONNECT_VALUE_CONVERTER: io.confluent.connect.avro.AvroConverter ## this is default value converter
      CONNECT_VALUE_CONVERTER_SCHEMA_REGISTRY_URL: "http://schema-registry:28081"
      CONNECT_INTERNAL_KEY_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_INTERNAL_VALUE_CONVERTER: "org.apache.kafka.connect.json.JsonConverter"
      CONNECT_LOG4J_ROOT_LOGLEVEL: "INFO"
      CONNECT_LOG4J_LOGGERS: "org.apache.kafka.connect.runtime.rest=WARN,org.reflections=ERROR"
      CONNECT_CONFIG_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_OFFSET_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_STATUS_STORAGE_REPLICATION_FACTOR: "1"
      CONNECT_PLUGIN_PATH: "/usr/share/java,/usr/share/confluent-hub-components/,/connectors/" ## this is the filepath for installing new plugins. Its hardcoded below for some reason.
      # If you want to use the Confluent Hub installer to d/l component, but make them available
      # when running this offline, spin up the stack once and then run :
      #   docker cp kafka-connect:/usr/share/confluent-hub-components ./connectors
      #   mv ./connectors/confluent-hub-components/* ./connectors
      #   rm -rf ./connectors/confluent-hub-components
    volumes:
      - $PWD/connectors:/connectors
      - $PWD/data/flatfiles:/data
    # In the command section, $ are replaced with $$ to avoid the error 'Invalid interpolation format for "command" option'
    networks:
      - kafka

  ksqldb:
    # docs: https://docs.ksqldb.io/en/latest/operate-and-deploy/installation/install-ksqldb-with-docker/
    # *-----------------------------*
    # To connect to the DB:
    #    docker exec -it ksqldb ksql http://ksqldb:8088
    # *-----------------------------*

    # image: confluentinc/ksqldb-server:0.8.0
    image: confluentinc/ksqldb-server:latest
    hostname: ksqldb
    container_name: ksqldb
    depends_on:
      - broker
      - kafka-connect
    ports:
      - 8088:8088
      - 28088:28088
    environment:
      KSQL_BOOTSTRAP_SERVERS: broker:29092 #,broker-2:29093,broker-3:29094,localhost:9092,localhost-2:9093,localhost-3:9094
      KSQL_LISTENERS: http://0.0.0.0:8088,http://localhost:8088,http://0.0.0.0:28088
      # KSQL_KSQL_SERVICE_ID: # The service ID of the ksqlDB server, which is used as the prefix for the internal topics created by ksqlDB. (e.g. ksql_standalone_1_)
      # KSQL_KSQL_QUERIES_FILE:  # A file that specifies predefined SQL queries.
      KEY_CONVERTER: org.apache.kafka.connect.storage.StringConverter
      KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE: "true"
      KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE: "true"
      KSQL_KSQL_CONNECT_URL: http://kafka-connect:28083,http://kafka-connect:8083
      KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:28081
      KSQL_KSQL_HIDDEN_TOPICS: "^_.*"    
    networks:
      - kafka







      # is this even necessary? - doesn't seem to be (can still run CLI commands to get into ksqldb)
  # ksqldb-cli:
  #   image: confluentinc/ksqldb-cli:0.7.1
  #   container_name: ksqldb-cli
  #   depends_on:
  #     - broker
  #     - ksqldb
  #   entrypoint: /bin/sh
  #   environment:
  #     KSQL_CONFIG_DIR: "/etc/ksql"
  #   tty: true
  #   volumes:  # for now standing queries will be saved in `src` directory on local machine
  #     - ./src:/opt/app/src
  #     # - ./test:/opt/app/test

  producer:
    build: ./producer
    depends_on:
      - broker
      - schema-registry
    environment: 
      BROKER: "broker.confluent_kafka:29092"
      SCHEMA_REGISTRY_URL: "http://schema-registry.confluent_kafka:28081"
    networks:
      - kafka

  # consumer:
  #   build: ./consumer
  #   depends_on:
  #     - broker
  #     - schema-registry
  #   environment: 
  #     BROKER: "broker.confluent_kafka:29092"
  #     SCHEMA_REGISTRY_URL: "http://schema-registry.confluent_kafka:28081"
  #   networks:
  #     - kafka

networks:
  kafka:
    # bridge is the default
    driver: bridge 

volumes:
  zk-data:
  zk-txn-logs:
  broker1-data:
  broker2-data:
  broker3-data:
  postgres-data: